{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9_CbSTbkGf5",
        "outputId": "20a025a5-2800-4135-87ce-e1cb6a528655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/lab05/Lab 5.zip\" -d \"content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWOOnhogktpe",
        "outputId": "d0f3f8ff-1ded-459c-f3d0-d3052ba6f162"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/lab05/Lab 5.zip\n",
            "   creating: content/Lab 5/\n",
            "  inflating: content/Lab 5/GOOG.csv  \n",
            "  inflating: content/Lab 5/IMDB Dataset.csv  \n",
            "  inflating: content/Lab 5/Q1.ipynb  \n",
            "  inflating: content/Lab 5/Q2.ipynb  \n",
            "  inflating: content/Lab 5/Q3.ipynb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "metadata": {
        "id": "OEJ2eBVVmI29"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Preprocess the Dataset\n",
        "def load_data(file_path):\n",
        "    # Load the dataset (e.g., IMDB movie reviews dataset)\n",
        "    df = pd.read_csv(file_path, engine='python', on_bad_lines='skip')  # Using 'python' engine and skipping bad lines\n",
        "    df.dropna(inplace=True)  # Drop any rows with missing values\n",
        "    return df['review'], df['sentiment']  # Assuming 'review' and 'sentiment' columns"
      ],
      "metadata": {
        "id": "fyAcfZp2mUFF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters, numbers, and symbols\n",
        "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "eGxCmSe6mYFt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and Pad Sequences\n",
        "def preprocess_text(reviews, max_words=5000, max_len=200):\n",
        "    reviews = [clean_text(review) for review in reviews]  # Clean the reviews\n",
        "    tokenizer = Tokenizer(num_words=max_words)\n",
        "    tokenizer.fit_on_texts(reviews)\n",
        "    sequences = tokenizer.texts_to_sequences(reviews)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "    return padded_sequences, tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "KXbOa2c4mZXt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Sentiments\n",
        "def encode_labels(sentiments):\n",
        "    sentiments = sentiments.map({'positive': 1, 'negative': 0}).values\n",
        "    return sentiments"
      ],
      "metadata": {
        "id": "yZdTkD-Yrv8W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"content/Lab 5\"))\n",
        "file_path = 'content/Lab 5/IMDB Dataset.csv'\n",
        "reviews, sentiments = load_data(file_path)\n"
      ],
      "metadata": {
        "id": "1UBy5xLRmbbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e052458c-5977-4a91-d651-d0a2f64f9623"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMDB Dataset.csv', 'Q2.ipynb', 'GOOG.csv', 'Q3.ipynb', 'Q1.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Text Data\n",
        "max_words = 5000  # Consider the top 5000 words\n",
        "max_len = 200  # Pad or truncate reviews to 200 words\n",
        "X, tokenizer = preprocess_text(reviews, max_words=max_words, max_len=max_len)"
      ],
      "metadata": {
        "id": "JGicpmdjme31"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Sentiments (positive -> 1, negative -> 0)\n",
        "y = encode_labels(sentiments)\n",
        "\n",
        "# Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "r6rJgqOHnbYu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define the LSTM Model\n",
        "model = Sequential()\n",
        "\n",
        "# Modify the embedding dimensions and experiment with LSTM configurations ---\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))  # <-- Modify 'output_dim'\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=False)))  # <-- Experiment with 'units' and add Dropout if necessary\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train the Model\n",
        "#  Modify 'epochs' and 'batch_size' to see how they impact training time and model accuracy ---\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)  # <-- Experiment with 'epochs' and 'batch_size'\n"
      ],
      "metadata": {
        "id": "srcMbfOJnnVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f6bed8-69b4-499c-e5bb-a1d836aa31b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 251ms/step - accuracy: 0.7462 - loss: 0.4907 - val_accuracy: 0.8733 - val_loss: 0.3000\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 261ms/step - accuracy: 0.8871 - loss: 0.2770 - val_accuracy: 0.8796 - val_loss: 0.2975\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 256ms/step - accuracy: 0.9137 - loss: 0.2191 - val_accuracy: 0.8743 - val_loss: 0.3099\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 264ms/step - accuracy: 0.9313 - loss: 0.1783 - val_accuracy: 0.8860 - val_loss: 0.3139\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 257ms/step - accuracy: 0.9473 - loss: 0.1422 - val_accuracy: 0.8862 - val_loss: 0.3129\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 256ms/step - accuracy: 0.9570 - loss: 0.1201 - val_accuracy: 0.8741 - val_loss: 0.3715\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 256ms/step - accuracy: 0.9660 - loss: 0.0964 - val_accuracy: 0.8756 - val_loss: 0.3695\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 252ms/step - accuracy: 0.9581 - loss: 0.1148 - val_accuracy: 0.8788 - val_loss: 0.4083\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 258ms/step - accuracy: 0.9819 - loss: 0.0572 - val_accuracy: 0.8693 - val_loss: 0.4722\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 254ms/step - accuracy: 0.9831 - loss: 0.0521 - val_accuracy: 0.8758 - val_loss: 0.5074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e5ad201cce0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the Model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XotNDVxjoAVN",
        "outputId": "7a88a806-508a-41e1-d550-5d64a10bc991"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Accuracy and F1-Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "\n",
        "\n",
        "#  Analyze the accuracy and F1-score. Consider modifying the model architecture or hyperparameters to improve performance ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYjAeL23Tdnz",
        "outputId": "c5b26839-0fbe-4719-9626-4ea7fffb7e7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8758\n",
            "F1-Score: 0.8781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Unidirectional LSTM Model\n",
        "# ===============================\n",
        "model_uni = Sequential()\n",
        "model_uni.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
        "model_uni.add(LSTM(units=64, return_sequences=False))  # Unidirectional\n",
        "model_uni.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_uni.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the Unidirectional model\n",
        "history_uni = model_uni.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10, batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Unidirectional model\n",
        "y_pred_uni = (model_uni.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "acc_uni = accuracy_score(y_test, y_pred_uni)\n",
        "f1_uni = f1_score(y_test, y_pred_uni)\n",
        "\n",
        "print(f'Unidirectional LSTM Accuracy: {acc_uni:.4f}')\n",
        "print(f'Unidirectional LSTM F1-Score: {f1_uni:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8AIyuRXhpyn",
        "outputId": "79ab7420-d9d1-41d8-fe2b-10707321c1b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 150ms/step - accuracy: 0.7579 - loss: 0.4916 - val_accuracy: 0.8716 - val_loss: 0.3113\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 152ms/step - accuracy: 0.8878 - loss: 0.2808 - val_accuracy: 0.8769 - val_loss: 0.2849\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 148ms/step - accuracy: 0.9111 - loss: 0.2292 - val_accuracy: 0.8689 - val_loss: 0.3181\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 146ms/step - accuracy: 0.9285 - loss: 0.1852 - val_accuracy: 0.8857 - val_loss: 0.3001\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 152ms/step - accuracy: 0.9452 - loss: 0.1448 - val_accuracy: 0.8750 - val_loss: 0.3291\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 149ms/step - accuracy: 0.9546 - loss: 0.1224 - val_accuracy: 0.8801 - val_loss: 0.3709\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 150ms/step - accuracy: 0.9669 - loss: 0.0943 - val_accuracy: 0.8779 - val_loss: 0.3774\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 150ms/step - accuracy: 0.9734 - loss: 0.0751 - val_accuracy: 0.8810 - val_loss: 0.3837\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 142ms/step - accuracy: 0.9785 - loss: 0.0634 - val_accuracy: 0.8719 - val_loss: 0.4270\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 151ms/step - accuracy: 0.9844 - loss: 0.0504 - val_accuracy: 0.8692 - val_loss: 0.4463\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step\n",
            "Unidirectional LSTM Accuracy: 0.8692\n",
            "Unidirectional LSTM F1-Score: 0.8701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison: Bidirectional vs Unidirectional LSTM\n",
        "\n",
        "### Results\n",
        "- **Bidirectional LSTM**\n",
        "  - Accuracy: 0.8758\n",
        "  - F1-score: 0.8781\n",
        "\n",
        "- **Unidirectional LSTM**\n",
        "  - Accuracy: 0.8692\n",
        "  - F1-score: 0.8701\n",
        "\n",
        "### Analysis\n",
        "- The **Bidirectional LSTM** performed slightly better in both accuracy and F1-score.\n",
        "- This improvement happens because it processes the text **from both directions (past + future context)**, which helps capture important sentiment cues (e.g., negations like *\"not good\"*).\n",
        "- The **Unidirectional LSTM** only reads text in the forward direction, so it sometimes misses context when important words appear later.\n",
        "- However, the performance gap is **small**, and the unidirectional model trains **faster** and is **less resource-intensive**.\n",
        "- For tasks where **efficiency is more important than slight performance gains**, the unidirectional model is still a strong option.\n"
      ],
      "metadata": {
        "id": "3bLnB6LqgMae"
      }
    }
  ]
}