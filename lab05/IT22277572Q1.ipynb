{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9_CbSTbkGf5",
        "outputId": "ecfadd28-95b7-4568-a255-cdb4d38f59e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/lab05/Lab 5.zip\" -d \"content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWOOnhogktpe",
        "outputId": "875cb9f7-1e7b-48a1-8c9f-9d886f8a017e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/lab05/Lab 5.zip\n",
            "   creating: content/Lab 5/\n",
            "  inflating: content/Lab 5/GOOG.csv  \n",
            "  inflating: content/Lab 5/IMDB Dataset.csv  \n",
            "  inflating: content/Lab 5/Q1.ipynb  \n",
            "  inflating: content/Lab 5/Q2.ipynb  \n",
            "  inflating: content/Lab 5/Q3.ipynb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "metadata": {
        "id": "OEJ2eBVVmI29"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Preprocess the Dataset\n",
        "def load_data(file_path):\n",
        "    # Load the dataset (e.g., IMDB movie reviews dataset)\n",
        "    df = pd.read_csv(file_path, engine='python', on_bad_lines='skip')  # Using 'python' engine and skipping bad lines\n",
        "    df.dropna(inplace=True)  # Drop any rows with missing values\n",
        "    return df['review'], df['sentiment']  # Assuming 'review' and 'sentiment' columns"
      ],
      "metadata": {
        "id": "fyAcfZp2mUFF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters, numbers, and symbols\n",
        "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "eGxCmSe6mYFt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and Pad Sequences\n",
        "def preprocess_text(reviews, max_words=5000, max_len=200):\n",
        "    reviews = [clean_text(review) for review in reviews]  # Clean the reviews\n",
        "    tokenizer = Tokenizer(num_words=max_words)\n",
        "    tokenizer.fit_on_texts(reviews)\n",
        "    sequences = tokenizer.texts_to_sequences(reviews)\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "    return padded_sequences, tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "KXbOa2c4mZXt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Sentiments\n",
        "def encode_labels(sentiments):\n",
        "    sentiments = sentiments.map({'positive': 1, 'negative': 0}).values\n",
        "    return sentiments"
      ],
      "metadata": {
        "id": "1UBy5xLRmbbW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"content/Lab 5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGicpmdjme31",
        "outputId": "01eee8ec-7295-401e-bff1-c39ddee9793e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMDB Dataset.csv', 'Q2.ipynb', 'GOOG.csv', 'Q3.ipynb', 'Q1.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'content/Lab 5/IMDB Dataset.csv'\n",
        "reviews, sentiments = load_data(file_path)\n"
      ],
      "metadata": {
        "id": "r6rJgqOHnbYu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Text Data\n",
        "max_words = 5000  # Consider the top 5000 words\n",
        "max_len = 200  # Pad or truncate reviews to 200 words\n",
        "X, tokenizer = preprocess_text(reviews, max_words=max_words, max_len=max_len)"
      ],
      "metadata": {
        "id": "srcMbfOJnnVF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Sentiments (positive -> 1, negative -> 0)\n",
        "y = encode_labels(sentiments)\n",
        "\n",
        "# Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6choKiS8nprd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define the LSTM Model\n",
        "model = Sequential()\n",
        "\n",
        "# Modify the embedding dimensions and experiment with LSTM configurations ---\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))  # <-- Modify 'output_dim'\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=False)))  # <-- Experiment with 'units' and add Dropout if necessary\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train the Model\n",
        "#  Modify 'epochs' and 'batch_size' to see how they impact training time and model accuracy ---\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)  # <-- Experiment with 'epochs' and 'batch_size'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWmbfUzDnxCO",
        "outputId": "5b2fbe29-c74b-4aaa-fbed-b597b86881ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 135ms/step - accuracy: 0.7591 - loss: 0.4796 - val_accuracy: 0.8577 - val_loss: 0.3426\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 143ms/step - accuracy: 0.8946 - loss: 0.2673 - val_accuracy: 0.8799 - val_loss: 0.2973\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 135ms/step - accuracy: 0.9185 - loss: 0.2121 - val_accuracy: 0.8870 - val_loss: 0.2809\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 136ms/step - accuracy: 0.9352 - loss: 0.1727 - val_accuracy: 0.8874 - val_loss: 0.2853\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 143ms/step - accuracy: 0.9506 - loss: 0.1349 - val_accuracy: 0.8760 - val_loss: 0.3402\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 143ms/step - accuracy: 0.9598 - loss: 0.1138 - val_accuracy: 0.8760 - val_loss: 0.3631\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 143ms/step - accuracy: 0.9747 - loss: 0.0752 - val_accuracy: 0.8652 - val_loss: 0.4513\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 143ms/step - accuracy: 0.9800 - loss: 0.0596 - val_accuracy: 0.8706 - val_loss: 0.4453\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 135ms/step - accuracy: 0.9844 - loss: 0.0500 - val_accuracy: 0.8738 - val_loss: 0.4792\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 143ms/step - accuracy: 0.9883 - loss: 0.0391 - val_accuracy: 0.8750 - val_loss: 0.5816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79bbb99c6090>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the Model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XotNDVxjoAVN",
        "outputId": "c05aa318-0bf6-4635-be2c-49c670934064"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Accuracy and F1-Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1-Score: {f1:.4f}')\n",
        "\n",
        "\n",
        "#  Analyze the accuracy and F1-score. Consider modifying the model architecture or hyperparameters to improve performance ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYfHHPBIoCFu",
        "outputId": "facb818c-bbd4-483f-85de-ca187320a216"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8750\n",
            "F1-Score: 0.8745\n"
          ]
        }
      ]
    }
  ]
}